#!/usr/bin/env python3
"""
Interactive Conversation Test for PrysmIOS Backend
Allows you to test the conversation system with topic selection and real-time chat.
"""

import json
import sys
import os
from datetime import datetime
from unittest.mock import Mock, patch

# Add the current directory to Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import functions from main.py
from main import build_system_prompt, format_conversation_history, generate_ai_response, gnews_top_headlines, gnews_search

# Available topics and subtopics - All GNews categories
AVAILABLE_TOPICS = {
    "general": {
        "fr": "gÃ©nÃ©ral",
        "es": "general",
        "ar": "Ø¹Ø§Ù…",
        "subtopics": {
            "en": ["Breaking News", "Top Stories", "Current Events", "Daily News", "Headlines"],
            "fr": ["ActualitÃ©s", "Principales Nouvelles", "Ã‰vÃ©nements Actuels", "Nouvelles Quotidiennes", "Gros Titres"],
            "es": ["Noticias de Ãšltima Hora", "Historias Principales", "Eventos Actuales", "Noticias Diarias", "Titulares"],
            "ar": ["Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ø¬Ù„Ø©", "Ø£Ù‡Ù… Ø§Ù„Ø£Ø®Ø¨Ø§Ø±", "Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø¬Ø§Ø±ÙŠØ©", "Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ÙŠÙˆÙ…ÙŠØ©", "Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"]
        }
    },
    "world": {
        "fr": "monde",
        "es": "mundo",
        "ar": "Ø¹Ø§Ù„Ù…",
        "subtopics": {
            "en": ["International News", "Global Events", "Foreign Affairs", "World Politics", "International Relations"],
            "fr": ["ActualitÃ©s Internationales", "Ã‰vÃ©nements Mondiaux", "Affaires Ã‰trangÃ¨res", "Politique Mondiale", "Relations Internationales"],
            "es": ["Noticias Internacionales", "Eventos Globales", "Asuntos Exteriores", "PolÃ­tica Mundial", "Relaciones Internacionales"],
            "ar": ["Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©", "Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©", "Ø§Ù„Ø´Ø¤ÙˆÙ† Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©", "Ø§Ù„Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©", "Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©"]
        }
    },
    "nation": {
        "fr": "national",
        "es": "nacional",
        "ar": "ÙˆØ·Ù†ÙŠ",
        "subtopics": {
            "en": ["Domestic Politics", "Government News", "National Elections", "Policy Changes", "Local Government"],
            "fr": ["Politique IntÃ©rieure", "ActualitÃ©s Gouvernementales", "Ã‰lections Nationales", "Changements de Politique", "Gouvernement Local"],
            "es": ["PolÃ­tica DomÃ©stica", "Noticias del Gobierno", "Elecciones Nacionales", "Cambios de PolÃ­tica", "Gobierno Local"],
            "ar": ["Ø§Ù„Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©", "Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø­ÙƒÙˆÙ…Ø©", "Ø§Ù„Ø§Ù†ØªØ®Ø§Ø¨Ø§Øª Ø§Ù„ÙˆØ·Ù†ÙŠØ©", "ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ø³ÙŠØ§Ø³Ø©", "Ø§Ù„Ø­ÙƒÙˆÙ…Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©"]
        }
    },
    "business": {
        "fr": "affaires",
        "es": "negocios",
        "ar": "Ø£Ø¹Ù…Ø§Ù„",
        "subtopics": {
            "en": ["Stock Market", "Startups", "Corporate News", "Economic Trends", "Cryptocurrency"],
            "fr": ["Bourse", "Startups", "ActualitÃ©s d'Entreprise", "Tendances Ã‰conomiques", "Cryptomonnaie"],
            "es": ["Bolsa de Valores", "Startups", "Noticias Corporativas", "Tendencias EconÃ³micas", "Criptomoneda"],
            "ar": ["Ø³ÙˆÙ‚ Ø§Ù„Ø£Ø³Ù‡Ù…", "Ø§Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„Ù†Ø§Ø´Ø¦Ø©", "Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø´Ø±ÙƒØ§Øª", "Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©", "Ø§Ù„Ø¹Ù…Ù„Ø© Ø§Ù„Ù…Ø´ÙØ±Ø©"]
        }
    },
    "technology": {
        "fr": "technologie",
        "es": "tecnologÃ­a", 
        "ar": "ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§",
        "subtopics": {
            "en": ["AI", "Smartphones & Gadgets", "Software Development", "Cybersecurity", "Tech Companies"],
            "fr": ["AI", "Smartphones & Gadgets", "DÃ©veloppement Logiciel", "CybersÃ©curitÃ©", "Entreprises Tech"],
            "es": ["AI", "Smartphones & Gadgets", "Desarrollo de Software", "Ciberseguridad", "Empresas Tech"],
            "ar": ["AI", "Ø§Ù„Ù‡ÙˆØ§ØªÙ Ø§Ù„Ø°ÙƒÙŠØ©", "ØªØ·ÙˆÙŠØ± Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ§Øª", "Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ", "Ø´Ø±ÙƒØ§Øª Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§"]
        }
    },
    "entertainment": {
        "fr": "divertissement",
        "es": "entretenimiento",
        "ar": "ØªØ±ÙÙŠÙ‡",
        "subtopics": {
            "en": ["Movies & TV", "Music", "Celebrities", "Gaming", "Arts & Culture"],
            "fr": ["Films & TV", "Musique", "CÃ©lÃ©britÃ©s", "Jeux VidÃ©o", "Arts & Culture"],
            "es": ["PelÃ­culas & TV", "MÃºsica", "Celebridades", "Videojuegos", "Arte & Cultura"],
            "ar": ["Ø£ÙÙ„Ø§Ù… ÙˆØªÙ„ÙØ²ÙŠÙˆÙ†", "Ù…ÙˆØ³ÙŠÙ‚Ù‰", "Ù…Ø´Ø§Ù‡ÙŠØ±", "Ø£Ù„Ø¹Ø§Ø¨", "ÙÙ†ÙˆÙ† ÙˆØ«Ù‚Ø§ÙØ©"]
        }
    },
    "sports": {
        "fr": "sport",
        "es": "deportes",
        "ar": "Ø±ÙŠØ§Ø¶Ø©",
        "subtopics": {
            "en": ["Football/Soccer", "Basketball", "Tennis", "Olympics", "Local Teams"],
            "fr": ["Football", "Basketball", "Tennis", "Jeux Olympiques", "Ã‰quipes Locales"],
            "es": ["FÃºtbol", "Baloncesto", "Tenis", "Juegos OlÃ­mpicos", "Equipos Locales"],
            "ar": ["ÙƒØ±Ø© Ø§Ù„Ù‚Ø¯Ù…", "ÙƒØ±Ø© Ø§Ù„Ø³Ù„Ø©", "Ø§Ù„ØªÙ†Ø³", "Ø§Ù„Ø£Ù„Ø¹Ø§Ø¨ Ø§Ù„Ø£ÙˆÙ„Ù…Ø¨ÙŠØ©", "Ø§Ù„ÙØ±Ù‚ Ø§Ù„Ù…Ø­Ù„ÙŠØ©"]
        }
    },
    "science": {
        "fr": "science",
        "es": "ciencia",
        "ar": "Ø¹Ù„ÙˆÙ…",
        "subtopics": {
            "en": ["Research", "Space & Astronomy", "Climate Change", "Biology", "Physics"],
            "fr": ["Recherche", "Espace & Astronomie", "Changement Climatique", "Biologie", "Physique"],
            "es": ["InvestigaciÃ³n", "Espacio & AstronomÃ­a", "Cambio ClimÃ¡tico", "BiologÃ­a", "FÃ­sica"],
            "ar": ["Ø¨Ø­Ø«", "Ø§Ù„ÙØ¶Ø§Ø¡ ÙˆØ§Ù„ÙÙ„Ùƒ", "ØªØºÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø®", "Ø¹Ù„Ù… Ø§Ù„Ø£Ø­ÙŠØ§Ø¡", "ÙÙŠØ²ÙŠØ§Ø¡"]
        }
    },
    "health": {
        "fr": "santÃ©",
        "es": "salud",
        "ar": "ØµØ­Ø©",
        "subtopics": {
            "en": ["Medical Research", "Public Health", "Mental Health", "Fitness & Wellness", "Healthcare Policy"],
            "fr": ["Recherche MÃ©dicale", "SantÃ© Publique", "SantÃ© Mentale", "Fitness & Bien-Ãªtre", "Politique de SantÃ©"],
            "es": ["InvestigaciÃ³n MÃ©dica", "Salud PÃºblica", "Salud Mental", "Fitness & Bienestar", "PolÃ­tica de Salud"],
            "ar": ["Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø·Ø¨ÙŠ", "Ø§Ù„ØµØ­Ø© Ø§Ù„Ø¹Ø§Ù…Ø©", "Ø§Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©", "Ø§Ù„Ù„ÙŠØ§Ù‚Ø© ÙˆØ§Ù„Ø¹Ø§ÙÙŠØ©", "Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ©"]
        }
    }
}

DETAIL_LEVELS = {
    "en": ["Light", "Medium", "Detailed"],
    "fr": ["LÃ©ger", "Moyen", "DÃ©taillÃ©"],
    "es": ["Ligero", "Medio", "Detallado"],
    "ar": ["Ø®ÙÙŠÙ", "Ù…ØªÙˆØ³Ø·", "Ù…ÙØµÙ„"]
}

LANGUAGES = {
    "en": "English",
    "fr": "FranÃ§ais", 
    "es": "EspaÃ±ol",
    "ar": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
}

def print_header():
    """Print the application header."""
    print("ğŸ¤– PrysmIOS Interactive Conversation Test")
    print("=" * 50)
    print("Test your conversation system with topic selection and real-time chat!")
    print()

def select_language():
    """Allow user to select language."""
    print("ğŸŒ Select your language / SÃ©lectionnez votre langue:")
    for i, (code, name) in enumerate(LANGUAGES.items(), 1):
        print(f"  {i}. {code.upper()} - {name}")
    
    while True:
        try:
            choice = input("\nEnter choice (1-4): ").strip()
            if choice in ['1', '2', '3', '4']:
                lang_codes = list(LANGUAGES.keys())
                selected_lang = lang_codes[int(choice) - 1]
                print(f"âœ… Selected: {LANGUAGES[selected_lang]}")
                return selected_lang
            else:
                print("âŒ Invalid choice. Please enter 1, 2, 3, or 4.")
        except (ValueError, KeyboardInterrupt):
            print("\nğŸ‘‹ Goodbye!")
            sys.exit(0)

def select_detail_level(language):
    """Allow user to select detail level."""
    levels = DETAIL_LEVELS[language]
    
    if language == "en":
        print("\nğŸ“Š Select your preferred detail level:")
    elif language == "fr":
        print("\nğŸ“Š SÃ©lectionnez votre niveau de dÃ©tail prÃ©fÃ©rÃ©:")
    elif language == "es":
        print("\nğŸ“Š Selecciona tu nivel de detalle preferido:")
    elif language == "ar":
        print("\nğŸ“Š Ø§Ø®ØªØ± Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙØµÙŠÙ„ Ø§Ù„Ù…ÙØ¶Ù„ Ù„Ø¯ÙŠÙƒ:")
    
    for i, level in enumerate(levels, 1):
        print(f"  {i}. {level}")
    
    while True:
        try:
            choice = input(f"\nEnter choice (1-{len(levels)}): ").strip()
            if choice in [str(i) for i in range(1, len(levels) + 1)]:
                selected_level = levels[int(choice) - 1]
                print(f"âœ… Selected: {selected_level}")
                # Convert back to English for internal use
                level_mapping = {v: k for k, v in zip(DETAIL_LEVELS["en"], levels)}
                return level_mapping[selected_level]
            else:
                print(f"âŒ Invalid choice. Please enter 1-{len(levels)}.")
        except (ValueError, KeyboardInterrupt):
            print("\nğŸ‘‹ Goodbye!")
            sys.exit(0)

def select_topics(language):
    """Allow user to select main topics."""
    if language == "en":
        print("\nğŸ“° Select your news topics (you can choose multiple):")
    elif language == "fr":
        print("\nğŸ“° SÃ©lectionnez vos sujets d'actualitÃ©s (vous pouvez en choisir plusieurs):")
    elif language == "es":
        print("\nğŸ“° Selecciona tus temas de noticias (puedes elegir varios):")
    elif language == "ar":
        print("\nğŸ“° Ø§Ø®ØªØ± Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø®ØªÙŠØ§Ø± Ø¹Ø¯Ø© Ù…ÙˆØ§Ø¶ÙŠØ¹):")
    
    # Display topics in selected language
    topic_list = []
    for i, (topic_key, topic_data) in enumerate(AVAILABLE_TOPICS.items(), 1):
        if language in topic_data:
            display_name = topic_data[language]
        else:
            display_name = topic_key
        print(f"  {i}. {display_name.title()}")
        topic_list.append(topic_key)
    
    if language == "en":
        print("\nEnter topic numbers separated by commas (e.g., 1,3,5):")
    elif language == "fr":
        print("\nEntrez les numÃ©ros des sujets sÃ©parÃ©s par des virgules (ex: 1,3,5):")
    elif language == "es":
        print("\nIngresa los nÃºmeros de temas separados por comas (ej: 1,3,5):")
    elif language == "ar":
        print("\nØ£Ø¯Ø®Ù„ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„ (Ù…Ø«Ø§Ù„: 1,3,5):")
    
    while True:
        try:
            choices = input("Your choice: ").strip().split(',')
            selected_topics = []
            selected_topic_keys = []
            
            for choice in choices:
                choice = choice.strip()
                if choice.isdigit() and 1 <= int(choice) <= len(topic_list):
                    topic_key = topic_list[int(choice) - 1]
                    selected_topic_keys.append(topic_key)
                    # Get display name in selected language
                    if language in AVAILABLE_TOPICS[topic_key]:
                        display_name = AVAILABLE_TOPICS[topic_key][language]
                    else:
                        display_name = topic_key
                    selected_topics.append(display_name)
                else:
                    print(f"âŒ Invalid choice: {choice}")
                    break
            else:
                if selected_topics:
                    print(f"âœ… Selected topics: {', '.join(selected_topics)}")
                    return selected_topics, selected_topic_keys
                else:
                    print("âŒ Please select at least one topic.")
        except (ValueError, KeyboardInterrupt):
            print("\nğŸ‘‹ Goodbye!")
            sys.exit(0)

def select_subtopics(selected_topic_keys, language):
    """Allow user to select subtopics for each main topic."""
    all_subtopics = []
    
    for topic_key in selected_topic_keys:
        topic_data = AVAILABLE_TOPICS[topic_key]
        
        # Get topic display name
        if language in topic_data:
            topic_display = topic_data[language]
        else:
            topic_display = topic_key
        
        # Get subtopics for this language
        subtopics = topic_data["subtopics"].get(language, topic_data["subtopics"]["en"])
        
        if language == "en":
            print(f"\nğŸ” Select specific interests for {topic_display.title()}:")
        elif language == "fr":
            print(f"\nğŸ” SÃ©lectionnez des intÃ©rÃªts spÃ©cifiques pour {topic_display.title()}:")
        elif language == "es":
            print(f"\nğŸ” Selecciona intereses especÃ­ficos para {topic_display.title()}:")
        elif language == "ar":
            print(f"\nğŸ” Ø§Ø®ØªØ± Ø§Ù‡ØªÙ…Ø§Ù…Ø§Øª Ù…Ø­Ø¯Ø¯Ø© Ù„Ù€ {topic_display.title()}:")
        
        for i, subtopic in enumerate(subtopics, 1):
            print(f"  {i}. {subtopic}")
        
        if language == "en":
            print(f"\nEnter subtopic numbers for {topic_display} (e.g., 1,3) or press Enter to skip:")
        elif language == "fr":
            print(f"\nEntrez les numÃ©ros des sous-sujets pour {topic_display} (ex: 1,3) ou EntrÃ©e pour passer:")
        elif language == "es":
            print(f"\nIngresa nÃºmeros de subtemas para {topic_display} (ej: 1,3) o Enter para omitir:")
        elif language == "ar":
            print(f"\nØ£Ø¯Ø®Ù„ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„ÙØ±Ø¹ÙŠØ© Ù„Ù€ {topic_display} (Ù…Ø«Ø§Ù„: 1,3) Ø£Ùˆ Enter Ù„Ù„ØªØ®Ø·ÙŠ:")
        
        while True:
            try:
                user_input = input("Your choice: ").strip()
                
                # Allow skipping
                if not user_input:
                    if language == "en":
                        print(f"â­ï¸ Skipped subtopics for {topic_display}")
                    elif language == "fr":
                        print(f"â­ï¸ Sous-sujets ignorÃ©s pour {topic_display}")
                    elif language == "es":
                        print(f"â­ï¸ Subtemas omitidos para {topic_display}")
                    elif language == "ar":
                        print(f"â­ï¸ ØªÙ… ØªØ®Ø·ÙŠ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„ÙØ±Ø¹ÙŠØ© Ù„Ù€ {topic_display}")
                    break
                
                choices = user_input.split(',')
                selected_subtopics = []
                
                for choice in choices:
                    choice = choice.strip()
                    if choice.isdigit() and 1 <= int(choice) <= len(subtopics):
                        subtopic = subtopics[int(choice) - 1]
                        selected_subtopics.append(f"{topic_display}: {subtopic}")
                    else:
                        print(f"âŒ Invalid choice: {choice}")
                        break
                else:
                    if selected_subtopics:
                        print(f"âœ… Selected for {topic_display}: {', '.join([s.split(': ')[1] for s in selected_subtopics])}")
                        all_subtopics.extend(selected_subtopics)
                    break
                    
            except (ValueError, KeyboardInterrupt):
                print("\nğŸ‘‹ Goodbye!")
                sys.exit(0)
    
    return all_subtopics

def fetch_trending_headlines(topics, subtopics, language="en"):
    """
    Fetch trending headlines for selected topics and subtopics.
    
    Args:
        topics (list): List of selected topics (display names)
        subtopics (list): List of selected subtopics (display names)
        language (str): Language code
    
    Returns:
        dict: Headlines organized by topics and subtopics
    """
    headlines = {
        "topics": {},
        "subtopics": {}
    }
    
    # Map language codes for GNews API
    gnews_lang_map = {
        "en": "en",
        "fr": "fr", 
        "es": "es",
        "ar": "ar"
    }
    
    # Map country codes
    gnews_country_map = {
        "en": "us",
        "fr": "fr",
        "es": "es", 
        "ar": "sa"
    }
    
    gnews_lang = gnews_lang_map.get(language, "en")
    gnews_country = gnews_country_map.get(language, "us")
    
    # Direct mapping of English topic keys to GNews categories
    topic_category_map = {
        "general": "general",
        "world": "world",
        "nation": "nation",
        "business": "business",
        "technology": "technology",
        "entertainment": "entertainment",
        "sports": "sports",
        "science": "science",
        "health": "health"
    }
    
    print(f"ğŸ” Fetching trending headlines for {language}...")
    
    # Fetch headlines for topics using top-headlines endpoint
    for topic in topics:
        try:
            # Find the English key for this topic
            topic_key = None
            for key, data in AVAILABLE_TOPICS.items():
                if language in data and data[language].lower() == topic.lower():
                    topic_key = key
                    break
                elif key.lower() == topic.lower():
                    topic_key = key
                    break
            
            if topic_key and topic_key in topic_category_map:
                category = topic_category_map[topic_key]
                response = gnews_top_headlines(
                    category=category,
                    lang=gnews_lang,
                    country=gnews_country,
                    max_articles=4
                )
                
                if response.get("success") and response.get("articles"):
                    headlines["topics"][topic] = [
                        article.get("title", "").strip() 
                        for article in response["articles"][:3]
                        if article.get("title")
                    ]
                    print(f"  âœ… {topic}: {len(headlines['topics'][topic])} headlines")
                else:
                    print(f"  âŒ {topic}: No headlines found")
                    
        except Exception as e:
            print(f"  âŒ {topic}: Error fetching headlines - {e}")
    
    # Fetch headlines for subtopics using search endpoint
    for subtopic in subtopics:
        try:
            # Extract the actual subtopic name (remove "topic: " prefix if present)
            clean_subtopic = subtopic.split(": ")[-1] if ": " in subtopic else subtopic
            
            response = gnews_search(
                query=clean_subtopic,
                lang=gnews_lang,
                country=gnews_country,
                max_articles=3
            )
            
            if response.get("success") and response.get("articles"):
                headlines["subtopics"][subtopic] = [
                    article.get("title", "").strip() 
                    for article in response["articles"][:2]
                    if article.get("title")
                ]
                print(f"  âœ… {clean_subtopic}: {len(headlines['subtopics'][subtopic])} headlines")
            else:
                print(f"  âŒ {clean_subtopic}: No headlines found")
                
        except Exception as e:
            print(f"  âŒ {clean_subtopic}: Error fetching headlines - {e}")
    
    return headlines

def build_enhanced_system_prompt(user_preferences, headlines=None):
    """
    Build enhanced system prompt with trending headlines.
    
    Args:
        user_preferences (dict): User preferences
        headlines (dict): Headlines organized by topics and subtopics
    
    Returns:
        str: Enhanced system prompt
    """
    # Get base system prompt
    base_prompt = build_system_prompt(user_preferences)
    
    if not headlines or (not headlines.get("topics") and not headlines.get("subtopics")):
        return base_prompt
    
    language = user_preferences.get('language', 'en')
    
    # Language-specific headlines section
    headlines_sections = {
        'en': {
            'intro': "\n\nCURRENT TRENDING HEADLINES (MUST mention these in your response):",
            'topics_header': "\nTrending in your selected topics:",
            'subtopics_header': "\nTrending in your subtopics:",
            'instruction': "\nIMPORTANT: You MUST mention these trending headlines in your response. Ask about specific companies, people, or events from these titles. Example: 'I see [specific company/person/event from headlines] is trending - are you interested in following them specifically?'"
        },
        'fr': {
            'intro': "\n\nTITRES TENDANCE ACTUELS (DOIT les mentionner dans votre rÃ©ponse):",
            'topics_header': "\nTendances dans vos sujets sÃ©lectionnÃ©s:",
            'subtopics_header': "\nTendances dans vos sous-sujets:",
            'instruction': "\nIMPORTANT: Vous DEVEZ mentionner ces titres tendance dans votre rÃ©ponse. Demandez sur des entreprises, personnes ou Ã©vÃ©nements spÃ©cifiques de ces titres. Exemple: 'Je vois que [entreprise/personne/Ã©vÃ©nement spÃ©cifique des titres] est tendance - Ãªtes-vous intÃ©ressÃ© Ã  les suivre spÃ©cifiquement?'"
        },
        'es': {
            'intro': "\n\nTITULARES TENDENCIA ACTUALES (DEBE mencionarlos en su respuesta):",
            'topics_header': "\nTendencias en tus temas seleccionados:",
            'subtopics_header': "\nTendencias en tus subtemas:",
            'instruction': "\nIMPORTANTE: DEBE mencionar estos titulares tendencia en su respuesta. Pregunte sobre empresas, personas o eventos especÃ­ficos de estos tÃ­tulos. Ejemplo: 'Veo que [empresa/persona/evento especÃ­fico de los titulares] estÃ¡ en tendencia - Â¿te interesa seguirlos especÃ­ficamente?'"
        },
        'ar': {
            'intro': "\n\nØ§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø±Ø§Ø¦Ø¬Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© (ÙŠØ¬Ø¨ Ø°ÙƒØ±Ù‡Ø§ ÙÙŠ Ø±Ø¯Ùƒ):",
            'topics_header': "\nØ§Ù„Ø±Ø§Ø¦Ø¬ ÙÙŠ Ù…ÙˆØ§Ø¶ÙŠØ¹Ùƒ Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©:",
            'subtopics_header': "\nØ§Ù„Ø±Ø§Ø¦Ø¬ ÙÙŠ Ù…ÙˆØ§Ø¶ÙŠØ¹Ùƒ Ø§Ù„ÙØ±Ø¹ÙŠØ©:",
            'instruction': "\nÙ…Ù‡Ù…: ÙŠØ¬Ø¨ Ø£Ù† ØªØ°ÙƒØ± Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø±Ø§Ø¦Ø¬Ø© ÙÙŠ Ø±Ø¯Ùƒ. Ø§Ø³Ø£Ù„ Ø¹Ù† Ø´Ø±ÙƒØ§Øª Ø£Ùˆ Ø£Ø´Ø®Ø§Øµ Ø£Ùˆ Ø£Ø­Ø¯Ø§Ø« Ù…Ø­Ø¯Ø¯Ø© Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†. Ù…Ø«Ø§Ù„: 'Ø£Ø±Ù‰ Ø£Ù† [Ø´Ø±ÙƒØ©/Ø´Ø®Øµ/Ø­Ø¯Ø« Ù…Ø­Ø¯Ø¯ Ù…Ù† Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†] Ø±Ø§Ø¦Ø¬ - Ù‡Ù„ ØªÙ‡ØªÙ… Ø¨Ù…ØªØ§Ø¨Ø¹ØªÙ‡Ù… ØªØ­Ø¯ÙŠØ¯Ø§Ù‹ØŸ'"
        }
    }
    
    section = headlines_sections.get(language, headlines_sections['en'])
    
    # Build headlines section
    headlines_text = section['intro']
    
    # Add topic headlines
    if headlines.get("topics"):
        headlines_text += section['topics_header']
        for topic, titles in headlines["topics"].items():
            if titles:
                headlines_text += f"\nâ€¢ {topic}:"
                for title in titles:
                    headlines_text += f"\n  - {title}"
    
    # Add subtopic headlines
    if headlines.get("subtopics"):
        headlines_text += section['subtopics_header']
        for subtopic, titles in headlines["subtopics"].items():
            if titles:
                headlines_text += f"\nâ€¢ {subtopic}:"
                for title in titles:
                    headlines_text += f"\n  - {title}"
    
    headlines_text += section['instruction']
    
    # Combine base prompt with headlines
    enhanced_prompt = base_prompt + headlines_text
    
    return enhanced_prompt

def mock_openai_response(user_message, language="en"):
    """Generate a mock AI response based on user message and language."""
    responses = {
        "en": {
            "hello": "Hello! I'm excited to help you with news and current events. Based on your preferences, I can provide personalized news updates. What specific aspects would you like to explore?",
            "technology": "Great choice! Technology is such a dynamic field. Are you particularly interested in AI developments, smartphone innovations, or perhaps specific tech companies like Apple, Google, or Microsoft?",
            "sports": "Sports news is always exciting! Are you interested in specific teams, leagues, or particular sports? For example, do you follow football/soccer, basketball, or maybe Olympic sports?",
            "politics": "Political news can be quite complex. Are you interested in international relations, domestic policy, elections, or specific regions? I can help you stay informed on the areas that matter most to you.",
            "business": "Business and economics are fascinating topics! Are you interested in stock market trends, startup news, corporate developments, or perhaps cryptocurrency and emerging markets?",
            "default": "That's interesting! Could you tell me more about what specific aspects of this topic interest you most? I'd love to help you get more targeted news updates."
        },
        "fr": {
            "hello": "Bonjour ! Je suis ravi de vous aider avec les actualitÃ©s et les Ã©vÃ©nements actuels. BasÃ© sur vos prÃ©fÃ©rences, je peux fournir des mises Ã  jour personnalisÃ©es. Quels aspects spÃ©cifiques aimeriez-vous explorer ?",
            "technology": "Excellent choix ! La technologie est un domaine si dynamique. ÃŠtes-vous particuliÃ¨rement intÃ©ressÃ© par les dÃ©veloppements de l'IA, les innovations smartphones, ou peut-Ãªtre des entreprises tech spÃ©cifiques comme Apple, Google ou Microsoft ?",
            "sports": "Les actualitÃ©s sportives sont toujours passionnantes ! ÃŠtes-vous intÃ©ressÃ© par des Ã©quipes spÃ©cifiques, des ligues, ou des sports particuliers ? Par exemple, suivez-vous le football, le basketball, ou peut-Ãªtre les sports olympiques ?",
            "default": "C'est intÃ©ressant ! Pourriez-vous me dire plus sur les aspects spÃ©cifiques de ce sujet qui vous intÃ©ressent le plus ? J'aimerais vous aider Ã  obtenir des mises Ã  jour d'actualitÃ©s plus ciblÃ©es."
        },
        "es": {
            "hello": "Â¡Hola! Estoy emocionado de ayudarte con noticias y eventos actuales. Basado en tus preferencias, puedo proporcionar actualizaciones personalizadas. Â¿QuÃ© aspectos especÃ­ficos te gustarÃ­a explorar?",
            "technology": "Â¡Excelente elecciÃ³n! La tecnologÃ­a es un campo tan dinÃ¡mico. Â¿EstÃ¡s particularmente interesado en desarrollos de IA, innovaciones en smartphones, o quizÃ¡s empresas tech especÃ­ficas como Apple, Google o Microsoft?",
            "default": "Â¡Eso es interesante! Â¿PodrÃ­as contarme mÃ¡s sobre quÃ© aspectos especÃ­ficos de este tema te interesan mÃ¡s? Me encantarÃ­a ayudarte a obtener actualizaciones de noticias mÃ¡s dirigidas."
        },
        "ar": {
            "hello": "Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ù…ØªØ­Ù…Ø³ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙˆØ§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø¬Ø§Ø±ÙŠØ©. Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙØ¶ÙŠÙ„Ø§ØªÙƒØŒ ÙŠÙ…ÙƒÙ†Ù†ÙŠ ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ø¯ÙŠØ«Ø§Øª Ù…Ø®ØµØµØ©. Ù…Ø§ Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø§Ù„ØªÙŠ ØªÙˆØ¯ Ø§Ø³ØªÙƒØ´Ø§ÙÙ‡Ø§ØŸ",
            "technology": "Ø§Ø®ØªÙŠØ§Ø± Ù…Ù…ØªØ§Ø²! Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ù…Ø¬Ø§Ù„ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø¬Ø¯Ø§Ù‹. Ù‡Ù„ Ø£Ù†Øª Ù…Ù‡ØªÙ… Ø¨Ø´ÙƒÙ„ Ø®Ø§Øµ Ø¨ØªØ·ÙˆØ±Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ø§Ø¨ØªÙƒØ§Ø±Ø§Øª Ø§Ù„Ù‡ÙˆØ§ØªÙ Ø§Ù„Ø°ÙƒÙŠØ©ØŒ Ø£Ùˆ Ø±Ø¨Ù…Ø§ Ø´Ø±ÙƒØ§Øª ØªÙ‚Ù†ÙŠØ© Ù…Ø­Ø¯Ø¯Ø© Ù…Ø«Ù„ Ø¢Ø¨Ù„ Ø£Ùˆ Ø¬ÙˆØ¬Ù„ Ø£Ùˆ Ù…Ø§ÙŠÙƒØ±ÙˆØ³ÙˆÙØªØŸ",
            "default": "Ù‡Ø°Ø§ Ù…Ø«ÙŠØ± Ù„Ù„Ø§Ù‡ØªÙ…Ø§Ù…! Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø®Ø¨Ø§Ø±ÙŠ Ø§Ù„Ù…Ø²ÙŠØ¯ Ø¹Ù† Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„ØªÙŠ ØªÙ‡Ù…Ùƒ Ø£ÙƒØ«Ø±ØŸ Ø£ÙˆØ¯ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ø¯ÙŠØ«Ø§Øª Ø¥Ø®Ø¨Ø§Ø±ÙŠØ© Ø£ÙƒØ«Ø± Ø§Ø³ØªÙ‡Ø¯Ø§ÙØ§Ù‹."
        }
    }
    
    lang_responses = responses.get(language, responses["en"])
    user_lower = user_message.lower()
    
    # Simple keyword matching for demo
    if any(word in user_lower for word in ["hello", "hi", "bonjour", "hola", "Ù…Ø±Ø­Ø¨Ø§"]):
        return lang_responses.get("hello", lang_responses["default"])
    elif any(word in user_lower for word in ["tech", "technologie", "tecnologÃ­a", "ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§"]):
        return lang_responses.get("technology", lang_responses["default"])
    elif any(word in user_lower for word in ["sport", "deportes", "Ø±ÙŠØ§Ø¶Ø©"]):
        return lang_responses.get("sports", lang_responses["default"])
    elif any(word in user_lower for word in ["politic", "politique", "polÃ­tica", "Ø³ÙŠØ§Ø³Ø©"]):
        return lang_responses.get("politics", lang_responses["default"])
    elif any(word in user_lower for word in ["business", "affaires", "negocios", "Ø£Ø¹Ù…Ø§Ù„"]):
        return lang_responses.get("business", lang_responses["default"])
    else:
        return lang_responses["default"]

def test_parallel_update(user_id, conversation_history, user_message, language):
    """
    Test the parallel update functionality for specific subjects.
    This simulates the background analysis that happens in the real system.
    """
    print(f"ğŸ” Testing parallel analysis for user {user_id}...")
    
    # Import the analysis function from main.py
    try:
        from main import analyze_conversation_for_specific_subjects, update_specific_subjects_in_db
        
        # Analyze conversation for specific subjects
        analysis_result = analyze_conversation_for_specific_subjects(
            conversation_history, user_message, language
        )
        
        if analysis_result["success"]:
            specific_subjects = analysis_result.get("specific_subjects", [])
            usage = analysis_result.get("usage", {})
            
            print(f"ğŸ“Š Analysis completed:")
            print(f"   - Subjects found: {specific_subjects}")
            print(f"   - Tokens used: {usage.get('total_tokens', 'N/A')}")
            
            if specific_subjects:
                print(f"ğŸ’¾ Simulating database update...")
                # In a real scenario, this would update Firebase Database
                # For testing, we'll just show what would be saved
                print(f"   - Would save to Firebase: {specific_subjects}")
                print(f"   - User ID: {user_id}")
                return {
                    "success": True,
                    "subjects_found": specific_subjects,
                    "analysis_usage": usage
                }
            else:
                print(f"   - No specific subjects found in this message")
                return {
                    "success": True,
                    "subjects_found": [],
                    "message": "No new subjects found"
                }
        else:
            error = analysis_result.get("error", "Unknown error")
            print(f"âŒ Analysis failed: {error}")
            return {
                "success": False,
                "error": error
            }
            
    except ImportError as e:
        print(f"âŒ Could not import analysis functions: {e}")
        print("ğŸ’¡ Make sure main.py is available and contains the analysis functions")
        return {
            "success": False,
            "error": f"Import error: {e}"
        }
    except Exception as e:
        print(f"âŒ Error during parallel analysis test: {e}")
        return {
            "success": False,
            "error": str(e)
        }

def start_conversation(user_preferences):
    """Start the interactive conversation using REAL OpenAI API."""
    language = user_preferences["language"]
    
    # Check if parallel testing is enabled
    enable_parallel_test = user_preferences.get("enable_parallel_test", False)
    
    # Generate a test user ID for parallel update testing (if enabled)
    test_user_id = None
    if enable_parallel_test:
        import uuid
        test_user_id = f"test_user_{str(uuid.uuid4())[:8]}"
    
    if language == "en":
        print("\nğŸ’¬ Starting conversation... (type 'quit' to exit)")
        print("ğŸ¤– AI Assistant is ready to chat with REAL OpenAI!")
        if enable_parallel_test:
            print(f"ğŸ†” Test User ID: {test_user_id}")
            print("ğŸ” Parallel analysis will be tested after each message")
    elif language == "fr":
        print("\nğŸ’¬ DÃ©marrage de la conversation... (tapez 'quit' pour quitter)")
        print("ğŸ¤– L'Assistant IA est prÃªt Ã  discuter avec la VRAIE OpenAI !")
        if enable_parallel_test:
            print(f"ğŸ†” ID Utilisateur Test: {test_user_id}")
            print("ğŸ” L'analyse parallÃ¨le sera testÃ©e aprÃ¨s chaque message")
    elif language == "es":
        print("\nğŸ’¬ Iniciando conversaciÃ³n... (escribe 'quit' para salir)")
        print("ğŸ¤– Â¡El Asistente IA estÃ¡ listo para chatear con OpenAI REAL!")
        if enable_parallel_test:
            print(f"ğŸ†” ID Usuario Prueba: {test_user_id}")
            print("ğŸ” El anÃ¡lisis paralelo se probarÃ¡ despuÃ©s de cada mensaje")
    elif language == "ar":
        print("\nğŸ’¬ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©... (Ø§ÙƒØªØ¨ 'quit' Ù„Ù„Ø®Ø±ÙˆØ¬)")
        print("ğŸ¤– Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¯Ø±Ø¯Ø´Ø© Ù…Ø¹ OpenAI Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ!")
        if enable_parallel_test:
            print(f"ğŸ†” Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ: {test_user_id}")
            print("ğŸ” Ø³ÙŠØªÙ… Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠ Ø¨Ø¹Ø¯ ÙƒÙ„ Ø±Ø³Ø§Ù„Ø©")
    
    print("-" * 50)
    
    # Fetch trending headlines for enhanced system prompt
    topics = user_preferences.get('subjects', [])
    subtopics = user_preferences.get('subtopics', [])
    language = user_preferences.get('language', 'en')
    
    headlines = fetch_trending_headlines(topics, subtopics, language)
    
    # Build enhanced system prompt with headlines
    system_prompt = build_enhanced_system_prompt(user_preferences, headlines)
    conversation_history = []
    
    # Show system prompt for debugging
    print(f"ğŸ”§ Enhanced System Prompt Generated ({len(system_prompt)} chars)")
    print(f"ğŸ“ Preview: {system_prompt[:150]}...")
    if headlines.get("topics") or headlines.get("subtopics"):
        total_headlines = sum(len(titles) for titles in headlines.get("topics", {}).values()) + sum(len(titles) for titles in headlines.get("subtopics", {}).values())
        print(f"ğŸ“° Headlines included: {total_headlines} trending articles")
    print("-" * 50)
    
    # Initial AI greeting using REAL OpenAI
    if language == "en":
        initial_message = "Hello! I'm ready to help you with personalized news based on your preferences."
    elif language == "fr":
        initial_message = "Bonjour ! Je suis prÃªt Ã  vous aider avec des actualitÃ©s personnalisÃ©es selon vos prÃ©fÃ©rences."
    elif language == "es":
        initial_message = "Â¡Hola! Estoy listo para ayudarte con noticias personalizadas segÃºn tus preferencias."
    elif language == "ar":
        initial_message = "Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ø¬Ø§Ù‡Ø² Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø®ØµØµØ© Ø­Ø³Ø¨ ØªÙØ¶ÙŠÙ„Ø§ØªÙƒ."
    
    print("ğŸ”„ Generating initial AI response...")
    ai_response_result = generate_ai_response(system_prompt, [], initial_message)
    
    if ai_response_result["success"]:
        initial_greeting = ai_response_result["message"]
        usage = ai_response_result.get("usage", {})
        print(f"ğŸ¤– AI: {initial_greeting}")
        print(f"ğŸ“Š Tokens used: {usage.get('total_tokens', 'N/A')}")
        conversation_history.append({"role": "assistant", "content": initial_greeting})
    else:
        print(f"âŒ Error generating initial response: {ai_response_result.get('error', 'Unknown error')}")
        print("ğŸ”„ Falling back to mock response...")
        initial_greeting = mock_openai_response("hello", language)
        print(f"ğŸ¤– AI (Mock): {initial_greeting}")
        conversation_history.append({"role": "assistant", "content": initial_greeting})
    
    while True:
        try:
            # Get user input
            if language == "en":
                user_input = input("\nğŸ‘¤ You: ").strip()
            elif language == "fr":
                user_input = input("\nğŸ‘¤ Vous: ").strip()
            elif language == "es":
                user_input = input("\nğŸ‘¤ TÃº: ").strip()
            elif language == "ar":
                user_input = input("\nğŸ‘¤ Ø£Ù†Øª: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'bye', 'au revoir', 'adiÃ³s', 'ÙˆØ¯Ø§Ø¹Ø§']:
                if language == "en":
                    print("\nğŸ‘‹ Thanks for testing the conversation system! Goodbye!")
                elif language == "fr":
                    print("\nğŸ‘‹ Merci d'avoir testÃ© le systÃ¨me de conversation ! Au revoir !")
                elif language == "es":
                    print("\nğŸ‘‹ Â¡Gracias por probar el sistema de conversaciÃ³n! Â¡AdiÃ³s!")
                elif language == "ar":
                    print("\nğŸ‘‹ Ø´ÙƒØ±Ø§Ù‹ Ù„Ùƒ Ø¹Ù„Ù‰ Ø§Ø®ØªØ¨Ø§Ø± Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©! ÙˆØ¯Ø§Ø¹Ø§Ù‹!")
                break
            
            if not user_input:
                continue
            
            # Add user message to history
            conversation_history.append({"role": "user", "content": user_input})
            
            # Test parallel analysis for specific subjects (if enabled)
            parallel_result = None
            if enable_parallel_test and test_user_id:
                print("\n" + "="*30 + " PARALLEL ANALYSIS TEST " + "="*30)
                parallel_result = test_parallel_update(
                    test_user_id, 
                    conversation_history[:-1],  # History without current message
                    user_input, 
                    language
                )
                print("="*80 + "\n")
            
            # Generate AI response using REAL backend function with enhanced prompt
            print("ğŸ”„ Generating AI response...")
            ai_response_result = generate_ai_response(system_prompt, conversation_history[:-1], user_input)
            
            if ai_response_result["success"]:
                ai_response = ai_response_result["message"]
                usage = ai_response_result.get("usage", {})
                
                # Display AI response
                print(f"ğŸ¤– AI: {ai_response}")
                print(f"ğŸ“Š Tokens: {usage.get('total_tokens', 'N/A')} (prompt: {usage.get('prompt_tokens', 'N/A')}, completion: {usage.get('completion_tokens', 'N/A')})")
                
                # Add AI response to history
                conversation_history.append({"role": "assistant", "content": ai_response})
            else:
                error_msg = ai_response_result.get("error", "Unknown error")
                print(f"âŒ Error generating AI response: {error_msg}")
                print("ğŸ”„ Falling back to mock response...")
                
                # Fallback to mock response
                ai_response = mock_openai_response(user_input, language)
                print(f"ğŸ¤– AI (Mock): {ai_response}")
                conversation_history.append({"role": "assistant", "content": ai_response})
            
            # Show parallel analysis summary
            if parallel_result and parallel_result.get("success"):
                subjects_found = parallel_result.get("subjects_found", [])
                if subjects_found:
                    if language == "en":
                        print(f"ğŸ¯ Specific subjects discovered: {', '.join(subjects_found)}")
                    elif language == "fr":
                        print(f"ğŸ¯ Sujets spÃ©cifiques dÃ©couverts: {', '.join(subjects_found)}")
                    elif language == "es":
                        print(f"ğŸ¯ Temas especÃ­ficos descubiertos: {', '.join(subjects_found)}")
                    elif language == "ar":
                        print(f"ğŸ¯ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {', '.join(subjects_found)}")
            
            # Show conversation stats
            if len(conversation_history) % 6 == 0:  # Every 3 exchanges
                if language == "en":
                    print(f"\nğŸ“Š Conversation stats: {len(conversation_history)} messages exchanged")
                elif language == "fr":
                    print(f"\nğŸ“Š Stats de conversation: {len(conversation_history)} messages Ã©changÃ©s")
                elif language == "es":
                    print(f"\nğŸ“Š EstadÃ­sticas de conversaciÃ³n: {len(conversation_history)} mensajes intercambiados")
                elif language == "ar":
                    print(f"\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©: {len(conversation_history)} Ø±Ø³Ø§Ù„Ø© Ù…ØªØ¨Ø§Ø¯Ù„Ø©")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Conversation interrupted. Goodbye!")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}")
            print("ğŸ”„ Continuing conversation...")
            continue

def check_openai_setup():
    """Check if OpenAI is properly configured."""
    from main import get_openai_client
    
    print("ğŸ” Checking OpenAI configuration...")
    client = get_openai_client()
    
    if client is None:
        print("âŒ OpenAI client not available!")
        print("ğŸ’¡ Make sure to set your OPENAI_API_KEY environment variable:")
        print("   export OPENAI_API_KEY='your-api-key-here'")
        print("ğŸ”„ Will use mock responses as fallback.")
        return False
    else:
        print("âœ… OpenAI client configured successfully!")
        return True

def main():
    """Main function to run the interactive test."""
    print_header()
    
    # Check OpenAI setup
    openai_available = check_openai_setup()
    print()
    
    try:
        # Step 1: Select language
        language = select_language()
        
        # Step 2: Select detail level
        detail_level = select_detail_level(language)
        
        # Step 3: Select topics
        topics, topic_keys = select_topics(language)
        
        # Step 4: Select subtopics
        subtopics = select_subtopics(topic_keys, language)
        
        # Build user preferences
        user_preferences = {
            "language": language,
            "detail_level": detail_level,
            "subjects": topics,
            "subtopics": subtopics
        }
        
        # Step 5: Ask about parallel testing
        if language == "en":
            test_parallel = input("\nğŸ” Test parallel analysis for specific subjects? (y/n): ").strip().lower()
        elif language == "fr":
            test_parallel = input("\nğŸ” Tester l'analyse parallÃ¨le pour les sujets spÃ©cifiques? (o/n): ").strip().lower()
        elif language == "es":
            test_parallel = input("\nğŸ” Â¿Probar anÃ¡lisis paralelo para temas especÃ­ficos? (s/n): ").strip().lower()
        elif language == "ar":
            test_parallel = input("\nğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠ Ù„Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©ØŸ (Ù†/Ù„): ").strip().lower()
        
        enable_parallel_test = test_parallel in ['y', 'yes', 'o', 'oui', 's', 'si', 'sÃ­', 'Ù†', 'Ù†Ø¹Ù…']
        
        # Add parallel testing flag to preferences
        user_preferences["enable_parallel_test"] = enable_parallel_test
        
        # Display summary
        print(f"\nğŸ“‹ Your Preferences Summary:")
        print(f"   Language: {LANGUAGES[language]}")
        print(f"   Detail Level: {detail_level}")
        print(f"   Topics: {', '.join(topics)}")
        print(f"   Subtopics: {', '.join(subtopics)}")
        print(f"   OpenAI Available: {'âœ… Yes' if openai_available else 'âŒ No (using mock)'}")
        print(f"   Parallel Testing: {'âœ… Enabled' if enable_parallel_test else 'âŒ Disabled'}")
        
        # Step 6: Start conversation
        start_conversation(user_preferences)
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Test interrupted. Goodbye!")
    except Exception as e:
        print(f"\nâŒ An error occurred: {e}")

if __name__ == "__main__":
    main() 