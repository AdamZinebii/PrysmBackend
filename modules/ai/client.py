"""
Client OpenAI et fonctions AI
"""

import sys
sys.stdout.write("--- main.py PYTHON SCRIPT STARTED (STDOUT) ---\n")
sys.stderr.write("--- main.py PYTHON SCRIPT STARTED (STDERR) ---\n")
print("--- main.py PYTHON SCRIPT STARTED (PRINT) ---")

# Configure logging AS EARLY AS POSSIBLE
import logging
logger = logging.getLogger(__name__)

# Welcome to Cloud Functions for Firebase for Python!
# Implementation of the Prysm backend for news aggregation

import openai

import json

from modules.database.operations import update_specific_subjects_in_db
from modules.config import get_openai_key


def get_openai_client():
    """Get configured OpenAI client."""
    try:
        api_key = get_openai_key()
        client = openai.OpenAI(api_key=api_key, timeout=30.0)
        logger.info("OpenAI client initialized successfully")
        return client
    except Exception as e:
        logger.error(f"Failed to initialize OpenAI client: {e}")
        return None

def generate_ai_response(system_prompt, conversation_history, user_message):
    """
    Generate AI response using OpenAI GPT.
    
    Args:
        system_prompt (str): System prompt for the conversation
        conversation_history (list): Previous messages in the conversation
        user_message (str): Current user message
    
    Returns:
        str: AI response or error message
    """
    try:
        client = get_openai_client()
        if not client:
            return "âŒ OpenAI client initialization failed"
        
        # Build messages array
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add conversation history
        if conversation_history:
            messages.extend(conversation_history)
        
        # Add current user message
        messages.append({"role": "user", "content": user_message})
        
        logger.info(f"ğŸ¤– Making OpenAI request with {len(messages)} messages")
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            max_tokens=1500,
            temperature=0.7
        )
        
        ai_response = response.choices[0].message.content.strip()
        logger.info(f"âœ… OpenAI response generated: {len(ai_response)} characters")
        
        return ai_response
        
    except Exception as e:
        logger.error(f"âŒ Error generating AI response: {e}")
        return f"âŒ Une erreur s'est produite lors de la gÃ©nÃ©ration de la rÃ©ponse: {str(e)}"

    
def build_system_prompt(user_preferences):
    """
    Build the system prompt based on user preferences.
    
    Args:
        user_preferences (dict): User preferences including subjects, subtopics, detail_level, language, specific_subjects, etc.
    
    Returns:
        str: Complete system prompt for the AI
    """
    subjects = user_preferences.get('subjects', [])
    subtopics = user_preferences.get('subtopics', [])
    specific_subjects = user_preferences.get('specific_subjects', [])
    detail_level = user_preferences.get('detail_level', 'Medium')
    language = user_preferences.get('language', 'en')
    
    # Language-specific prompts
    language_prompts = {
        'en': {
            'role': "You are a preferences discovery assistant for PrysmIOS app.",
            'task': "Your ONLY goal is to discover the user's specific news interests and preferences. DO NOT provide news articles or current events. Keep responses SHORT (max 3-4 sentences).",
            'guide': "Ask questions to understand what specific topics, companies, people, or events they want to follow. Be proactive in discovering their interests.",
            'subjects_intro': "User selected:",
            'subtopics_intro': "Subtopics:",
            'detail_intro': f"Detail level: {detail_level.lower()}.",
            'refinement_task': "Ask about specific entities they want to follow from their topics. Examples: 'Which tech companies interest you?' or 'Any specific sports teams you follow?'",
            'guidelines': "DISCOVER PREFERENCES, DON'T GIVE NEWS! Examples: Technology â†’ Ask 'Which tech companies like Apple, Tesla, or OpenAI interest you?' Sports â†’ Ask 'Do you follow specific teams like Lakers or players like Messi?'",
            'conversation_flow': "When you have enough specific interests, say: 'Perfect! I've learned about your interests. Your personalized news feed is ready!'"
        },
        'fr': {
            'role': "Tu es un assistant de dÃ©couverte de prÃ©fÃ©rences pour l'application PrysmIOS.",
            'task': "Ton SEUL objectif est de dÃ©couvrir les intÃ©rÃªts et prÃ©fÃ©rences spÃ©cifiques de l'utilisateur. NE DONNE PAS d'articles d'actualitÃ©s ou d'Ã©vÃ©nements actuels. Reste BREF (max 3-4 phrases).",
            'guide': "Pose des questions pour comprendre quels sujets spÃ©cifiques, entreprises, personnes ou Ã©vÃ©nements ils veulent suivre. Sois proactif dans la dÃ©couverte de leurs intÃ©rÃªts.",
            'subjects_intro': "Utilisateur a choisi :",
            'subtopics_intro': "Sous-sujets :",
            'detail_intro': f"Niveau de dÃ©tail : {detail_level.lower()}.",
            'refinement_task': "Demande quelles entitÃ©s spÃ©cifiques ils veulent suivre dans leurs sujets. Exemples : 'Quelles entreprises tech t'intÃ©ressent ?' ou 'Tu suis des Ã©quipes sportives particuliÃ¨res ?'",
            'guidelines': "DÃ‰COUVRE LES PRÃ‰FÃ‰RENCES, NE DONNE PAS D'ACTUALITÃ‰S ! Exemples : Technologie â†’ Demande 'Quelles entreprises comme Apple, Tesla ou OpenAI t'intÃ©ressent ?' Sport â†’ Demande 'Tu suis des Ã©quipes comme Real Madrid ou des joueurs comme Messi ?'",
            'conversation_flow': "Quand tu as assez d'intÃ©rÃªts spÃ©cifiques, dis : 'Parfait ! J'ai appris tes intÃ©rÃªts. Ton flux d'actualitÃ©s personnalisÃ© est prÃªt !'"
        },
        'es': {
            'role': "Eres un asistente de descubrimiento de preferencias para la aplicaciÃ³n PrysmIOS.",
            'task': "Tu ÃšNICO objetivo es descubrir los intereses y preferencias especÃ­ficos del usuario. NO proporciones artÃ­culos de noticias o eventos actuales. Mantente BREVE (mÃ¡x 3-4 frases).",
            'guide': "Haz preguntas para entender quÃ© temas especÃ­ficos, empresas, personas o eventos quieren seguir. SÃ© proactivo en descubrir sus intereses.",
            'subjects_intro': "Usuario eligiÃ³:",
            'subtopics_intro': "Subtemas:",
            'detail_intro': f"Nivel de detalle: {detail_level.lower()}.",
            'refinement_task': "Pregunta quÃ© entidades especÃ­ficas quieren seguir de sus temas. Ejemplos: 'Â¿QuÃ© empresas tecnolÃ³gicas te interesan?' o 'Â¿Sigues equipos deportivos especÃ­ficos?'",
            'guidelines': "Â¡DESCUBRE PREFERENCIAS, NO DES NOTICIAS! Ejemplos: TecnologÃ­a â†’ Pregunta 'Â¿QuÃ© empresas como Apple, Tesla u OpenAI te interesan?' Deportes â†’ Pregunta 'Â¿Sigues equipos como Real Madrid o jugadores como Messi?'",
            'conversation_flow': "Cuando tengas suficientes intereses especÃ­ficos, di: 'Â¡Perfecto! He aprendido sobre tus intereses. Â¡Tu feed de noticias personalizado estÃ¡ listo!'"
        },
        'ar': {
            'role': "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ØªÙØ¶ÙŠÙ„Ø§Øª Ù„ØªØ·Ø¨ÙŠÙ‚ PrysmIOS.",
            'task': "Ù‡Ø¯ÙÙƒ Ø§Ù„ÙˆØ­ÙŠØ¯ Ù‡Ùˆ Ø§ÙƒØªØ´Ø§Ù Ø§Ù‡ØªÙ…Ø§Ù…Ø§Øª ÙˆØªÙØ¶ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©. Ù„Ø§ ØªÙ‚Ø¯Ù… Ù…Ù‚Ø§Ù„Ø§Øª Ø¥Ø®Ø¨Ø§Ø±ÙŠØ© Ø£Ùˆ Ø£Ø­Ø¯Ø§Ø« Ø¬Ø§Ø±ÙŠØ©. ÙƒÙ† Ù…Ø®ØªØµØ±Ø§Ù‹ (Ø­Ø¯ Ø£Ù‚ØµÙ‰ 3-4 Ø¬Ù…Ù„).",
            'guide': "Ø§Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© Ù„ÙÙ‡Ù… Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙˆØ§Ù„Ø´Ø±ÙƒØ§Øª ÙˆØ§Ù„Ø£Ø´Ø®Ø§Øµ Ø£Ùˆ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„ØªÙŠ ÙŠØ±ÙŠØ¯ÙˆÙ† Ù…ØªØ§Ø¨Ø¹ØªÙ‡Ø§. ÙƒÙ† Ø§Ø³ØªØ¨Ø§Ù‚ÙŠØ§Ù‹ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù‡ØªÙ…Ø§Ù…Ø§ØªÙ‡Ù….",
            'subjects_intro': "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ø®ØªØ§Ø±:",
            'subtopics_intro': "Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„ÙØ±Ø¹ÙŠØ©:",
            'detail_intro': f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙØµÙŠÙ„: {detail_level.lower()}.",
            'refinement_task': "Ø§Ø³Ø£Ù„ Ø¹Ù† Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø§Ù„ØªÙŠ ÙŠØ±ÙŠØ¯ÙˆÙ† Ù…ØªØ§Ø¨Ø¹ØªÙ‡Ø§ Ù…Ù† Ù…ÙˆØ§Ø¶ÙŠØ¹Ù‡Ù…. Ø£Ù…Ø«Ù„Ø©: 'Ù…Ø§ Ø§Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø§Ù„ØªÙŠ ØªÙ‡Ù…ÙƒØŸ' Ø£Ùˆ 'Ù‡Ù„ ØªØªØ§Ø¨Ø¹ ÙØ±Ù‚ Ø±ÙŠØ§Ø¶ÙŠØ© Ù…Ø¹ÙŠÙ†Ø©ØŸ'",
            'guidelines': "Ø§ÙƒØªØ´Ù Ø§Ù„ØªÙØ¶ÙŠÙ„Ø§ØªØŒ Ù„Ø§ ØªØ¹Ø·Ù Ø£Ø®Ø¨Ø§Ø±Ø§Ù‹! Ø£Ù…Ø«Ù„Ø©: Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ â†’ Ø§Ø³Ø£Ù„ 'Ù…Ø§ Ø§Ù„Ø´Ø±ÙƒØ§Øª Ù…Ø«Ù„ Ø¢Ø¨Ù„ Ø£Ùˆ ØªØ³Ù„Ø§ Ø£Ùˆ OpenAI Ø§Ù„ØªÙŠ ØªÙ‡Ù…ÙƒØŸ' Ø§Ù„Ø±ÙŠØ§Ø¶Ø© â†’ Ø§Ø³Ø£Ù„ 'Ù‡Ù„ ØªØªØ§Ø¨Ø¹ ÙØ±Ù‚ Ù…Ø«Ù„ Ø±ÙŠØ§Ù„ Ù…Ø¯Ø±ÙŠØ¯ Ø£Ùˆ Ù„Ø§Ø¹Ø¨ÙŠÙ† Ù…Ø«Ù„ Ù…ÙŠØ³ÙŠØŸ'",
            'conversation_flow': "Ø¹Ù†Ø¯Ù…Ø§ ØªØ­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù‡ØªÙ…Ø§Ù…Ø§Øª Ù…Ø­Ø¯Ø¯Ø© ÙƒØ§ÙÙŠØ©ØŒ Ù‚Ù„: 'Ù…Ù…ØªØ§Ø²! Ù„Ù‚Ø¯ ØªØ¹Ù„Ù…Øª Ø¹Ù† Ø§Ù‡ØªÙ…Ø§Ù…Ø§ØªÙƒ. ØªØ¯ÙÙ‚ Ø£Ø®Ø¨Ø§Ø±Ùƒ Ø§Ù„Ø´Ø®ØµÙŠ Ø¬Ø§Ù‡Ø²!'"
        }
    }
    
    prompt_data = language_prompts.get(language, language_prompts['en'])
    
    # Build the complete system prompt
    system_prompt = f"""IMPORTANT: You are NOT a news provider. You do NOT give news articles, headlines, or current events.

{prompt_data['role']}

{prompt_data['task']}

{prompt_data['guide']}

{prompt_data['subjects_intro']} {', '.join(subjects) if subjects else 'None specified'}

"""
    
    # Add subtopics if available
    if subtopics:
        system_prompt += f"{prompt_data['subtopics_intro']} {', '.join(subtopics)}\n\n"
    
    system_prompt += f"""{prompt_data['detail_intro']}

{prompt_data['refinement_task']}

{prompt_data['guidelines']}

{prompt_data['conversation_flow']}"""
    
    return system_prompt

def format_conversation_history(messages):
    """
    Format conversation history for OpenAI API.
    
    Args:
        messages (list): List of message objects with 'role' and 'content'
    
    Returns:
        list: Formatted messages for OpenAI API
    """
    formatted_messages = []
    
    for message in messages:
        role = message.get('role', '').lower()
        content = message.get('content', '')
        
        # Map roles to OpenAI format
        if role in ['user', 'human']:
            formatted_messages.append({"role": "user", "content": content})
        elif role in ['assistant', 'chatbot', 'ai']:
            formatted_messages.append({"role": "assistant", "content": content})
        elif role == 'system':
            formatted_messages.append({"role": "system", "content": content})
    
    return formatted_messages


def analyze_conversation_for_specific_subjects(conversation_history, user_message, language='en'):
    """
    Analyze conversation to extract specific subjects using a separate LLM call.
    
    Args:
        conversation_history (list): Previous conversation messages
        user_message (str): Current user message
        language (str): Language code for analysis
    
    Returns:
        dict: Analysis result with extracted subjects
    """
    try:
        client = get_openai_client()
        if not client:
            return {"success": False, "error": "OpenAI client not available"}
        
        # Build analysis prompt based on language
        analysis_prompts = {
            'en': """CRITICAL TASK: Extract ONLY specific entities that the USER explicitly mentions in their messages.

RULES:
1. Look ONLY at messages that start with "user:"
2. Extract ONLY what the user explicitly names or mentions
3. IGNORE everything the assistant says
4. Extract specific names, companies, people, products, events, AND specific technologies

What to extract (ONLY if user mentions them):
- Company names: "Tesla", "Apple", "Microsoft", "OpenAI", "Google"
- People names: "Elon Musk", "Tim Cook", "Biden", "Cristiano Ronaldo"
- Products: "iPhone", "ChatGPT", "PlayStation", "Rubik's Cube"
- Events: "Olympics 2024", "CES", "World Cup"
- Specific technologies: "LLMs", "GPT-4", "machine learning", "AI", "robotique", "robot"
- Specific topics: "robot qui a battu le record", "innovations en robotique"

What NOT to extract:
- Very general concepts like "technology", "sports" (without specifics)
- Things only the assistant mentioned
- Implied topics not explicitly mentioned

IMPORTANT: If user says "LLMs", "robot", "robotique", "machine learning", "AI" - these ARE specific enough to extract.

Return ONLY a JSON array of specific entities the USER explicitly mentioned: ["entity1", "entity2"]
If user mentioned no specific entities, return: []""",
            
            'fr': """TÃ‚CHE CRITIQUE: Extraire SEULEMENT les entitÃ©s spÃ©cifiques que l'UTILISATEUR mentionne explicitement dans ses messages.

RÃˆGLES:
1. Regarde SEULEMENT les messages qui commencent par "user:"
2. Extrait SEULEMENT ce que l'utilisateur nomme ou mentionne explicitement
3. IGNORE tout ce que l'assistant dit
4. Extrait les noms spÃ©cifiques, entreprises, personnes, produits, Ã©vÃ©nements, ET technologies spÃ©cifiques

Quoi extraire (SEULEMENT si l'utilisateur les mentionne):
- Noms d'entreprises: "Tesla", "Apple", "Microsoft", "OpenAI", "Google"
- Noms de personnes: "Elon Musk", "Tim Cook", "Biden", "Cristiano Ronaldo"
- Produits: "iPhone", "ChatGPT", "PlayStation", "Rubik's Cube"
- Ã‰vÃ©nements: "Jeux Olympiques 2024", "CES", "Coupe du Monde"
- Technologies spÃ©cifiques: "LLMs", "GPT-4", "apprentissage automatique", "IA", "robotique", "robot"
- Sujets spÃ©cifiques: "robot qui a battu le record", "innovations en robotique"

Quoi NE PAS extraire:
- Concepts trÃ¨s gÃ©nÃ©raux comme "technologie", "sport" (sans spÃ©cificitÃ©s)
- Choses mentionnÃ©es seulement par l'assistant
- Sujets impliquÃ©s ou suggÃ©rÃ©s

IMPORTANT: Si l'utilisateur dit "LLMs", "robot", "robotique", "apprentissage automatique", "IA" - ces termes SONT assez spÃ©cifiques pour Ãªtre extraits.

Retourne SEULEMENT un array JSON d'entitÃ©s spÃ©cifiques que l'UTILISATEUR a explicitement mentionnÃ©es: ["entitÃ©1", "entitÃ©2"]
Si l'utilisateur n'a mentionnÃ© aucune entitÃ© spÃ©cifique, retourne: []""",
            
            'es': """TAREA CRÃTICA: Extraer SOLO entidades especÃ­ficas que el USUARIO menciona explÃ­citamente en sus mensajes.

REGLAS:
1. Mira SOLO mensajes que empiecen con "user:"
2. Extrae SOLO lo que el usuario nombra o menciona explÃ­citamente
3. IGNORA todo lo que dice el asistente
4. IGNORA temas generales como "IA", "tecnologÃ­a", "deportes"
5. Extrae SOLO nombres especÃ­ficos, empresas, personas, productos, eventos

QuÃ© extraer (SOLO si el usuario los menciona):
- Nombres de empresas: "Tesla", "Apple", "Microsoft"
- Nombres de personas: "Elon Musk", "Tim Cook", "Biden"
- Productos: "iPhone", "ChatGPT", "PlayStation"
- Eventos: "Olimpiadas 2024", "CES", "Copa Mundial"
- TecnologÃ­as especÃ­ficas: "LLMs" (si el usuario lo dice), "GPT-4"

QuÃ© NO extraer:
- Conceptos generales: "IA", "tecnologÃ­a", "aprendizaje automÃ¡tico"
- Cosas mencionadas solo por el asistente
- Temas implÃ­citos o sugeridos

Devuelve SOLO un array JSON de entidades especÃ­ficas que el USUARIO mencionÃ³ explÃ­citamente: ["entidad1", "entidad2"]
Si el usuario no mencionÃ³ entidades especÃ­ficas, devuelve: []""",
            
            'ar': """Ù…Ù‡Ù…Ø© Ø­Ø§Ø³Ù…Ø©: Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙÙ‚Ø· Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø§Ù„ØªÙŠ ÙŠØ°ÙƒØ±Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØµØ±Ø§Ø­Ø© ÙÙŠ Ø±Ø³Ø§Ø¦Ù„Ù‡.

Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯:
1. Ø§Ù†Ø¸Ø± ÙÙ‚Ø· Ø¥Ù„Ù‰ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„ØªÙŠ ØªØ¨Ø¯Ø£ Ø¨Ù€ "user:"
2. Ø§Ø³ØªØ®Ø±Ø¬ ÙÙ‚Ø· Ù…Ø§ ÙŠØ³Ù…ÙŠÙ‡ Ø£Ùˆ ÙŠØ°ÙƒØ±Ù‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØµØ±Ø§Ø­Ø©
3. ØªØ¬Ø§Ù‡Ù„ ÙƒÙ„ Ù…Ø§ ÙŠÙ‚ÙˆÙ„Ù‡ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯
4. ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø¹Ø§Ù…Ø© Ù…Ø«Ù„ "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"ØŒ "Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§"ØŒ "Ø§Ù„Ø±ÙŠØ§Ø¶Ø©"
5. Ø§Ø³ØªØ®Ø±Ø¬ ÙÙ‚Ø· Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©ØŒ Ø§Ù„Ø´Ø±ÙƒØ§ØªØŒ Ø§Ù„Ø£Ø´Ø®Ø§ØµØŒ Ø§Ù„Ù…Ù†ØªØ¬Ø§ØªØŒ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«

Ù…Ø§ ÙŠØ¬Ø¨ Ø§Ø³ØªØ®Ø±Ø§Ø¬Ù‡ (ÙÙ‚Ø· Ø¥Ø°Ø§ Ø°ÙƒØ±Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…):
- Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´Ø±ÙƒØ§Øª: "ØªØ³Ù„Ø§"ØŒ "Ø¢Ø¨Ù„"ØŒ "Ù…Ø§ÙŠÙƒØ±ÙˆØ³ÙˆÙØª"
- Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø´Ø®Ø§Øµ: "Ø¥ÙŠÙ„ÙˆÙ† Ù…Ø§Ø³Ùƒ"ØŒ "ØªÙŠÙ… ÙƒÙˆÙƒ"ØŒ "Ø¨Ø§ÙŠØ¯Ù†"
- Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª: "Ø¢ÙŠÙÙˆÙ†"ØŒ "ChatGPT"ØŒ "Ø¨Ù„Ø§ÙŠØ³ØªÙŠØ´Ù†"
- Ø§Ù„Ø£Ø­Ø¯Ø§Ø«: "Ø£ÙˆÙ„Ù…Ø¨ÙŠØ§Ø¯ 2024"ØŒ "CES"ØŒ "ÙƒØ£Ø³ Ø§Ù„Ø¹Ø§Ù„Ù…"
- Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©: "LLMs" (Ø¥Ø°Ø§ Ù‚Ø§Ù„Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…)ØŒ "GPT-4"

Ù…Ø§ Ù„Ø§ ÙŠØ¬Ø¨ Ø§Ø³ØªØ®Ø±Ø§Ø¬Ù‡:
- Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø¹Ø§Ù…Ø©: "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"ØŒ "Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§"ØŒ "Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"
- Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ Ø§Ù„ØªÙŠ Ø°ÙƒØ±Ù‡Ø§ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ ÙÙ‚Ø·
- Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø¶Ù…Ù†ÙŠØ© Ø£Ùˆ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©

Ø£Ø±Ø¬Ø¹ ÙÙ‚Ø· Ù…ØµÙÙˆÙØ© JSON Ù„Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø§Ù„ØªÙŠ Ø°ÙƒØ±Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØµØ±Ø§Ø­Ø©: ["ÙƒÙŠØ§Ù†1", "ÙƒÙŠØ§Ù†2"]
Ø¥Ø°Ø§ Ù„Ù… ÙŠØ°ÙƒØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£ÙŠ ÙƒÙŠØ§Ù†Ø§Øª Ù…Ø­Ø¯Ø¯Ø©ØŒ Ø£Ø±Ø¬Ø¹: []"""
        }
        
        analysis_prompt = analysis_prompts.get(language, analysis_prompts['en'])
        
        # Build conversation context
        conversation_text = ""
        for msg in conversation_history[-5:]:  # Last 5 messages for context
            role = msg.get('role', '')
            content = msg.get('content', '')
            conversation_text += f"{role}: {content}\n"
        
        conversation_text += f"user: {user_message}\n"
        
        # Create analysis messages
        messages = [
            {"role": "system", "content": analysis_prompt},
            {"role": "user", "content": f"Conversation to analyze:\n{conversation_text}"}
        ]
        
        # Generate analysis
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=200,
            temperature=0.3
        )
        
        analysis_result = response.choices[0].message.content.strip()
        
        # Try to parse JSON
        try:
            specific_subjects = json.loads(analysis_result)
            if isinstance(specific_subjects, list):
                # Filter out empty strings and duplicates
                specific_subjects = list(set([s.strip() for s in specific_subjects if s.strip()]))
                
                return {
                    "success": True,
                    "specific_subjects": specific_subjects,
                    "usage": {
                        "prompt_tokens": response.usage.prompt_tokens,
                        "completion_tokens": response.usage.completion_tokens,
                        "total_tokens": response.usage.total_tokens
                    }
                }
            else:
                return {"success": False, "error": "Invalid response format"}
                
        except json.JSONDecodeError:
            logger.warning(f"Failed to parse analysis result as JSON: {analysis_result}")
            return {"success": False, "error": "Failed to parse analysis result"}
            
    except Exception as e:
        logger.error(f"Error analyzing conversation for specific subjects: {e}")
        return {"success": False, "error": str(e)}

# --- Background Analysis Helper ---

def analyze_and_update_specific_subjects(user_id, conversation_history, user_message, language):
    """
    Background function to analyze conversation and update specific subjects.
    This runs in a separate thread to not block the main conversation response.
    """
    try:
        logger.info(f"Background analysis started for user {user_id}")
        
        # Analyze conversation for specific subjects
        analysis_result = analyze_conversation_for_specific_subjects(
            conversation_history, user_message, language
        )
        
        if analysis_result["success"] and analysis_result.get("specific_subjects"):
            # Update database with new specific subjects
            update_result = update_specific_subjects_in_db(
                user_id, analysis_result["specific_subjects"]
            )
            
            if update_result["success"]:
                logger.info(f"Background analysis completed for user {user_id}. New subjects: {analysis_result['specific_subjects']}")
        else:
            logger.info(f"Background analysis completed for user {user_id}. No new subjects found.")
            
    except Exception as e:
        logger.error(f"Error in background analysis for user {user_id}: {e}")
